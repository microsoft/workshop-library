{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Regression Challenge\n",
                "\n",
                "Predicting the selling price of a residential property depends on a number of factors, including the property age, availability of local amenities, and location.\n",
                "\n",
                "In this challenge, you will use a dataset of real estate sales transactions to predict the price-per-unit of a property based on its features. The price-per-unit in this data is based on a unit measurement of 3.3 square meters.\n",
                "\n",
                "> **Citation**: The data used in this exercise originates from the following study:\n",
                ">\n",
                "> *Yeh, I. C., & Hsu, T. K. (2018). Building real estate valuation models with comparative approach through case-based reasoning. Applied Soft Computing, 65, 260-271.*\n",
                ">\n",
                "> It was obtained from the UCI dataset repository (Dua, D. and Graff, C. (2019). [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml). Irvine, CA: University of California, School of Information and Computer Science).\n",
                "\n",
                "## Review the data\n",
                "\n",
                "Let's hit the ground running by importing the data and viewing the first few rows.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load the core tidyverse and tidymodels in your current R session\n",
                "suppressPackageStartupMessages({\n",
                " library(tidyverse)\n",
                " library(tidymodels)\n",
                "})\n",
                "\n",
                "# Read the csv file into a tibble\n",
                "estate_data <- read_csv(file = \"https://raw.githubusercontent.com/MicrosoftDocs/ml-basics/master/challenges/data/real_estate.csv\", \n",
                "show_col_types = FALSE)\n",
                "\n",
                "# Print the first 10 rows of the data\n",
                "estate_data %>%\n",
                " slice_head(n = 10)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The data consists of the following variables:\n",
                "\n",
                "-   **transaction_date** - the transaction date (for example, 2013.250=2013 March, 2013.500=2013 June, etc.)\n",
                "\n",
                "-   **house_age** - the house age (in years)\n",
                "\n",
                "-   **transit_distance** - the distance to the nearest light rail station (in meters)\n",
                "\n",
                "-   **local_convenience_stores** - the number of convenience stores within walking distance\n",
                "\n",
                "-   **latitude** - the geographic coordinate, latitude\n",
                "\n",
                "-   **longitude** - the geographic coordinate, longitude\n",
                "\n",
                "-   **price_per_unit** house price of unit area (3.3 square meters)\n",
                "\n",
                "Your challenge is to explore and prepare the data, identify predictive features that will help predict the `price_per_unit` label, and train a regression model that achieves the lowest *Root Mean Square Error* (RMSE) you can achieve (which must be less than *7*) when evaluated against a test subset of data.\n",
                "\n",
                "### View the label distribution\n",
                "\n",
                "Let's start our analysis of the data by examining a few key descriptive statistics. We can use the `summarytools::descr()` function to neatly and quickly summarize the numeric features as well as the *rentals* label column.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load summary tools library\n",
                "library(summarytools)\n",
                "\n",
                "# Obtain summary stats for feature and label columns\n",
                "estate_data %>%\n",
                "  # Summary stats\n",
                "  descr(order = \"preserve\",\n",
                "        stats = c(\"mean\", \"sd\", \"min\", \"q1\", \"med\", \"q3\", \"max\"),\n",
                "        round.digits = 6)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The statistics reveal some information about the distribution of the data in each of the numeric fields, including the number of observations (there are 414 records), the mean, standard deviation, minimum and maximum values, and the quantile values (the threshold values for 25%, 50% - which is also the median, and 75% of the data).\n",
                "\n",
                "From this, we can see that the mean number of price per unit is around 38. There's a comparatively *small standard deviation*, indicating *not much variance* in the prices per unit.\n",
                "\n",
                "We might get a clearer idea of the distribution of price values by visualizing the data.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "library(patchwork)\n",
                "\n",
                "# Plot a histogram\n",
                "theme_set(theme_light())\n",
                "\n",
                "hist_plt <- estate_data %>%\n",
                "  ggplot(mapping = aes(x = price_per_unit)) +\n",
                "  geom_histogram(bins = 100, fill = \"midnightblue\", alpha = 0.7) +\n",
                "\n",
                "  # Add lines for mean and median\n",
                "  geom_vline(aes(xintercept = mean(price_per_unit), color = \"Mean\"),\n",
                " linetype = \"dashed\", size = 1.3) +\n",
                "  geom_vline(aes(xintercept = median(price_per_unit), color = \"Median\"),\n",
                " linetype = \"dashed\", size = 1.3) +\n",
                "  xlab(\"\") +\n",
                "  ylab(\"Frequency\") +\n",
                "  scale_color_manual(name = \"\", values = c(Mean = \"red\", Median = \"yellow\")) +\n",
                "  theme(legend.position = c(0.9, 0.9), legend.background = element_blank())\n",
                "\n",
                "# Plot a box plot\n",
                "box_plt <- estate_data %>%\n",
                "  ggplot(aes(x = price_per_unit, y = 1)) +\n",
                "  geom_boxplot(fill = \"#E69F00\", color = \"gray23\", alpha = 0.7) +\n",
                "    # Add titles and labels\n",
                "  xlab(\"Price_per_unit\") +\n",
                "  ylab(\"\")\n",
                "\n",
                "\n",
                "# Combine plots using patchwork syntax\n",
                "(hist_plt / box_plt) +\n",
                "  plot_annotation(title = \"Price Distribution\",\n",
                "                  theme = theme(\n",
                "                    plot.title = element_text(hjust = 0.5)))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "What can we observe from the boxplot? Yes, outliers.\n",
                "\n",
                "### Remove outliers\n",
                "\n",
                "We are now set to begin writing some code ourselves üôÇ. Let's begin by dealing with outliers. An outlier is a data point that differs significantly from other observations.\n",
                "\n",
                "**Question 1.**\n",
                "\n",
                "Starting with the `estate_data` dataset, `filter` to create a subset that contains observations where `price_per_unit` is less than *70*.\n",
                "\n",
                "Fill in the placeholder `....` with the right code."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Narrow down to observations whose price_per_unit is less than 70\n",
                "estate_data <- estate_data %>%\n",
                "  ....\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Test your answer:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                ". <- ottr::check(\"tests/Question 1.R\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now let's take a look at the distribution without the outliers.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot a histogram\n",
                "theme_set(theme_light())\n",
                "hist_plt <- estate_data %>%\n",
                "  ggplot(mapping = aes(x = price_per_unit)) + \n",
                "  geom_histogram(bins = 100, fill = \"midnightblue\", alpha = 0.7) +\n",
                "\n",
                "  # Add lines for mean and median\n",
                "  geom_vline(aes(xintercept = mean(price_per_unit), color = \"Mean\"),\n",
                " linetype = \"dashed\", size = 1.3) +\n",
                "  geom_vline(aes(xintercept = median(price_per_unit), color = \"Median\"),\n",
                " linetype = \"dashed\", size = 1.3) +\n",
                "  xlab(\"\") +\n",
                "  ylab(\"Frequency\") +\n",
                "  scale_color_manual(name = \"\", values = c(Mean = \"red\", Median = \"yellow\")) +\n",
                "  theme(legend.position = c(0.9, 0.9), legend.background = element_blank())\n",
                "\n",
                "# Plot a box plot\n",
                "box_plt <- estate_data %>%\n",
                "  ggplot(aes(x = price_per_unit, y = 1)) +\n",
                "  geom_boxplot(fill = \"#E69F00\", color = \"gray23\", alpha = 0.7) +\n",
                "    # Add titles and labels\n",
                "  xlab(\"Price_per_unit\") +\n",
                "  ylab(\"\")\n",
                "\n",
                "\n",
                "# Combine plots using patchwork syntax\n",
                "(hist_plt / box_plt) +\n",
                "  plot_annotation(title = \"Price Distribution\",\n",
                "                  theme = theme(\n",
                "                    plot.title = element_text(hjust = 0.5)))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Much better ü§©! What can we say about the distribution of the price?\n",
                "\n",
                "### View numeric correlations\n",
                "\n",
                "We can now start to look for relationships between the *features* and the *label* we want to be able to predict.\n",
                "\n",
                "The *correlation* statistic, *r*, is a value between -1 and 1 that indicates the strength of a linear relationship.\n",
                "\n",
                "For numeric feature and label columns, we can create scatter plots that show the intersection of the feature and label values.\n",
                "\n",
                "**Question 2.**\n",
                "\n",
                "Starting with the `estate_data` dataset, in a piped sequence:\n",
                "\n",
                "- `pivot_longer` the data (increase the number of rows and decrease the number of columns) such that all the existing column names except price_per_unit, now fall under a new column name called `features` and their corresponding values under a new column name `values`\n",
                "\n",
                "-   group the data by `features`\n",
                "\n",
                "-   add a new column `corr_coef` which calculates the correlation between `values` and `price_per_unit` (hint: the function used for calculating correlation in R is `cor()`)\n",
                "\n",
                "Fill in the placeholder `....` with the right code."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Pivot numeric features to a long format\n",
                "numeric_features_long <- estate_data %>%\n",
                "  pivot_....(!price_per_unit, names_to = \"....\", values_to = \"....\") %>%\n",
                "  # Group by features\n",
                "  ....(features) %>%\n",
                "  # Calculate correlation coefficient between values and price_per_unit\n",
                "  mutate(corr_coef = ....) %>%\n",
                "\n",
                "  # Modifies the feature column to also include corr_coef\n",
                "  mutate(features = paste(features, \"vs price, r = \",\n",
                " round(corr_coef, 2), sep = \"\")) %>%\n",
                "  ungroup()\n",
                "\n",
                "# Print the first few rows of the data\n",
                "numeric_features_long %>%\n",
                "  slice_head(n = 10)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Test your answer:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                ". <- ottr::check(\"tests/Question 2.R\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Fantastic! Now let's use a scatter plot to investigate whether there is any linear relationship between our predictors and outcome variables.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot a scatter plot for each feature\n",
                "numeric_features_long %>%\n",
                "  ggplot(aes(x = values, y = price_per_unit, color = features)) +\n",
                "  geom_point(alpha = 0.7, show.legend = F) +\n",
                "  facet_wrap(~ features, scales = \"free\") +\n",
                "  paletteer::scale_color_paletteer_d(\"ggthemes::excel_Parallax\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Take a moment and go through the scatter plot. How does the correlation between these features and the price vary?\n",
                "\n",
                "### View categorical features\n",
                "\n",
                "Now let's compare the categorical features to the label. We'll do this by creating box plots that show the distribution of rental counts for each category.\n",
                "\n",
                "`Transaction_date` and `local_convenience_stores` seem to be discrete values - so might work better if treated as categorical features. Let' get right into it.\n",
                "\n",
                "**Question 3.**\n",
                "\n",
                "Starting with the `estate_data` dataset, in a piped sequence:\n",
                "\n",
                "-   only keep columns `transaction_date`, `local_convenience_stores` and `price_per_unit`\n",
                "\n",
                "-   encode columns `transaction_date` and `local_convenience_stores` as categorical (factor)\n",
                "\n",
                "-   `pivot_longer` the data (increase the number of rows and decrease the number of columns) such that all the existing column names except price_per_unit now fall under a new column name called `features` and their corresponding values under a new column name `values`\n",
                "\n",
                "Fill in the placeholder `....` with the right code."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Pivot categorical features to a long format\n",
                "cat_features_long <- estate_data %>%\n",
                "  ....(transaction_date, ...., ....) %>%\n",
                "  # Encode transaction_date & local_convenience_stores features\n",
                "  # from numeric to categorical\n",
                "  mutate(....) %>%\n",
                "  pivot_longer(....)\n",
                "\n",
                "# Print some observations\n",
                "cat_features_long %>%\n",
                "  slice_head(n = 10)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Test your answer:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                ". <- ottr::check(\"tests/Question 3.R\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Perfect! Now, for our categorical features, boxplots can be a great way of visualising how the price per unit varies within the levels of the categorical feature.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot a box plot for each feature\n",
                "cat_features_long %>%\n",
                "  ggplot() +\n",
                "  geom_boxplot(aes(x = values, y = price_per_unit, fill = features),\n",
                " alpha = 0.7, show.legend = F) +\n",
                "  facet_wrap(~ features, scales = \"free\") +\n",
                "  scale_fill_viridis_d() +\n",
                "  theme(panel.grid = element_blank(),\n",
                "        axis.text.x = element_text(angle = 90))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Take a moment and interpret the graphics. How does the price vary with these features?\n",
                "\n",
                "## Split the data into training and test sets.\n",
                "\n",
                "Now that we've explored the data, it's time to use it to train a regression model that uses the features we've identified as *potentially predictive* to predict the `price_per_unit` label.\n",
                "\n",
                "`Transaction_date` doesn't seem to be very predictive, so we'll omit it.\n",
                "\n",
                "Let's begin by splitting the data set such that some goes to training and some goes for validation. This enables us to evaluate how well the model performs in order to get a better estimate of how your models will perform on new data.\n",
                "\n",
                "**Question 4.**\n",
                "\n",
                "In this section:\n",
                "\n",
                "-   Make a split specification of `estate_data` such that *70%* goes to training and the rest goes to testing. Save this to a variable name `estate_split`\n",
                "\n",
                "-   Extract the training and testing sets from `estate_split` and save them in `estate_train` and `estate_test` variable names respectively.\n",
                "\n",
                "Fill in the placeholder `....` with the right code."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Set seed to ensure reproducibility and consistency of outputs\n",
                "set.seed(2056)\n",
                "\n",
                "# Load the tidymodels package\n",
                "library(tidymodels)\n",
                "\n",
                "# Split 70% of the data for training and the rest for tesing\n",
                "estate_split <- estate_data %>%\n",
                "  initial_split(....)\n",
                "\n",
                "# Extract the train and test data in each split\n",
                "estate_train <- ....(estate_split)\n",
                "estate_test <- ....(estate_split)\n",
                "\n",
                "# Print the number of observations in each split\n",
                "cat(\"Training Set\", nrow(estate_train), \"rows\",\n",
                "    \"\\nTest Set\", nrow(estate_test), \"rows\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Test your answer:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                ". <- ottr::check(\"tests/Question 4.R\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Great progress üí™! Now let's train some models.\n",
                "\n",
                "## Train a regression model\n",
                "\n",
                "### Preprocess data using recipes\n",
                "\n",
                "Often before fitting a model, we may want to reformat the predictor values to make them easier for a model to use effectively. This includes transformations and encodings of the data to best represent their important characteristics. In R,this is done using a `recipe`.\n",
                "\n",
                "A recipe is an object that defines a series of steps for data processing.\n",
                "\n",
                "**Question 5.**\n",
                "\n",
                "In this section, specify a recipe, `estate_recipe`, that will:\n",
                "\n",
                "-   Remove the `transaction_date` feature\n",
                "\n",
                "-   Transform `local_convenience_stores` feature into categorical (factor)\n",
                "\n",
                "-   Center and scale all numeric predictors\n",
                "\n",
                "Fill in the placeholder `....` with the right code."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create a preprocessing recipe\n",
                "estate_recipe <- ....(price_per_unit ~ ., data = estate_train) %>%\n",
                "  # Specify the removal of transaction_date\n",
                "  step_rm(....) %>%\n",
                "  # Specify the encoding of local_convenience_stores as categorical\n",
                "  step_mutate(\n",
                "    local_convenience_stores = ....) %>%\n",
                "  # Specify the normalization of numeric features\n",
                "  ....(all_numeric_predictors())\n",
                " \n",
                "# Print recipe\n",
                "estate_recipe\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Test your answer:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                ". <- ottr::check(\"tests/Question 5.R\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Fantastic! We have the data processing in order. Now, let's make a model specification. In this solution, we'll try out a random forest model which applies an averaging function to multiple decision tree models for a better overall model.\n",
                "\n",
                "**Question 6.**\n",
                "\n",
                "Create a random forest model specification, `rf_spec`, which uses the `randomForest` package as its engine and then set the mode to `regression`.\n",
                "\n",
                "Fill in the placeholder `....` with the right code."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Build a random forest model specification\n",
                "rf_spec <- rand_forest() %>%\n",
                "  # Specify engine\n",
                "  .... %>%\n",
                "  # Specify mode\n",
                "  set_mode(\"....\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Test your answer:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                ". <- ottr::check(\"tests/Question 6.R\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Create a modeling workflow\n",
                "\n",
                "The *workflows* package allows the user to bind modeling and preprocessing objects together. You can then fit the entire workflow to the data, so that the model encapsulates all of the preprocessing steps as well as the algorithm.\n",
                "\n",
                "**Question 7.**\n",
                "\n",
                "Components of a `workflow()` go together like LEGO blocks. In this section, create a workflow container and then add the preprocessing information from our recipe and then add the model specification to be trained.\n",
                "\n",
                "Fill in the placeholder `....` with the right code."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create a workflow that bundles a recipe and model specification\n",
                "rf_workflow <- workflow() %>%\n",
                "  # Add a recipe\n",
                "  add_recipe(....) %>%\n",
                "  # Add a model specification\n",
                "  ....\n",
                "# Print workflow\n",
                "rf_workflow\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Test your answer:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                ". <- ottr::check(\"tests/Question 7.R\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now that we have everything (recipe + model specification) wrapped together nicely in a workflow, we are ready to train a model. Workflows have a `fit()` method that can be used to train a model.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# For reproducibility\n",
                "set.seed(2056)\n",
                "\n",
                "# Train a random forest model\n",
                "rf_workflow_fit <- rf_workflow %>%\n",
                "  fit(data = estate_train)\n",
                "\n",
                "# Print out the fitted workflow\n",
                "rf_workflow_fit\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Excellent! So we now have a trained random forest model; but is it any good? Let's evaluate its performance! We'll do this by making predictions on the `test data` and then evaluate some performance metrics based on the actual outcomes.\n",
                "\n",
                "**Question 8.**\n",
                "\n",
                "-   We'll evaluate the model performance based on the *rmse* and *rsq* metrics. Use the `metric_set()` function to combine these metric functions together into a new function, `eval_metrics`, that calculates all of them at once.\n",
                "\n",
                "-   Generate predictions for the test data and then bind them to the test set. Rename the column containing predictions from `.pred` to `predictions`.\n",
                "\n",
                "Fill in the placeholder `....` with the right code."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create a metric set\n",
                "eval_metrics <- ....(rmse, ....)\n",
                "\n",
                "\n",
                "# Make and bind predictions to test data\n",
                "results <- rf_workflow_fit %>%\n",
                "  ....\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Test your answer:\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                ". <- ottr::check(\"tests/Question 8.R\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Awesome work! You have just used your trained model to make predictions on the test set.\n",
                "\n",
                "How well did the model predict the prices per unit? Let's find out by looking at the metrics.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluate the model\n",
                "rf_metrics <- eval_metrics(data = results,\n",
                "                           truth = price_per_unit,\n",
                "                           estimate = predictions)\n",
                "\n",
                "\n",
                "# Plot predicted vs actual\n",
                "rf_plt <- results %>%\n",
                "  ggplot(mapping = aes(x = price_per_unit, y = predictions)) +\n",
                "  geom_point(color = \"darkorchid\", size = 1.6) +\n",
                "  # overlay regression line\n",
                "  geom_smooth(method = \"lm\", color = \"black\", se = F) +\n",
                "  ggtitle(\"Price per unit predictions\") +\n",
                "  xlab(\"Actual Labels\") +\n",
                "  ylab(\"Predicted Labels\") +\n",
                "  theme(plot.title = element_text(hjust = 0.5))\n",
                "\n",
                "# Return evaluations\n",
                "list(metrics = rf_metrics, evaluation_plot = rf_plt)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "How do you think the model performed? What do the values for `rsq` and `rmse` tell you? Please refer to the corresponding module for this notebook if you may need help answering these questions.\n",
                "\n",
                "## Use the Trained Model\n",
                "\n",
                "Save your trained model, and then use it to predict the price-per-unit for the following real estate transactions:\n",
                "\n",
                "| **transaction_date** | **house_age** | **transit_distance** | **local_convenience_stores** | **latitude** | **longitude** |\n",
                "|----------------------|---------------|----------------------|------------------------------|--------------|---------------|\n",
                "| 2013.167             | 16.2          | 289.3248             | 5                            | 24.98203     | 121.54348     |\n",
                "| 2013.000             | 13.6          | 4082.015             | 0                            | 24.94155     | 121.50381     |\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "library(here)\n",
                "# Save trained workflow\n",
                "saveRDS(rf_workflow_fit, \"rf_price_model.rds\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In this way, we can load it whenever we need it, and use it to predict labels for new data. This is often called *scoring* or *inferencing*.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create a tibble for the new real estate samples\n",
                "new_data <- tibble(\n",
                "  transaction_date = c(2013.167, 2013.000),\n",
                "  house_age = c(16.2, 13.6),\n",
                "  transit_distance = c(289.3248, 4082.015),\n",
                "  local_convenience_stores = c(5, 0),\n",
                "  latitude = c(24.98203, 24.94155),\n",
                "  longitude = c(121.54348, 121.50381))\n",
                "\n",
                "# Print out new data\n",
                "new_data\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now that we have our data, let's load the saved model and make predictions.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load the model into the current R session\n",
                "loaded_model <- readRDS(\"rf_price_model.rds\")\n",
                "\n",
                "# Make predictions\n",
                "predictions <- loaded_model %>%\n",
                "  augment(new_data = new_data)\n",
                "\n",
                "predictions\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Congratulations for completing this challenge! In this notebook, you:\n",
                "\n",
                "-   Explored the data set to understand the relationships between the predictors and outcomes\n",
                "-   Preprocessed the data using recipes to make them easier for a model to use effectively.\n",
                "-   Made a random forest model specification.\n",
                "-   Bundles a recipe and model specification into a workflow.\n",
                "-   Trained a model.\n",
                "-   Made predictions on test set and evaluated the model performance.\n",
                "-   Saved the model, loaded it and then used it to predict labels for new data.\n",
                "\n",
                "Fantastic job for coming this far üëè! Feeling adventurous? Then, be sure to try out other regression models and tune some hyperparameters while at it.\n",
                "\n",
                "See you in our next module as we explore the realm of *classification* models!\n",
                "\n",
                "Happy Learning,\n",
                "\n",
                "[Eric](https://twitter.com/ericntay), Gold Microsoft Learn Student Ambassador.\n"
            ]
        }
    ],
    "metadata": {
        "anaconda-cloud": "",
        "kernelspec": {
            "display_name": "R",
            "language": "R",
            "name": "ir"
        },
        "language_info": {
            "codemirror_mode": "r",
            "file_extension": ".r",
            "mimetype": "text/x-r-source",
            "name": "R",
            "pygments_lexer": "r",
            "version": "3.4.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}
